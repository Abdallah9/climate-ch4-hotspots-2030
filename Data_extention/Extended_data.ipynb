{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf4454e-e7a1-49bf-8712-688b104c0ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023\n",
      " 2024]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"Unified_Climate_Dataset_2010-2024_ML_READY_5.csv\")\n",
    "print(df[\"year\"].unique())   # should show 2010–2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e081c7-52da-4575-8a93-26df033c6070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29be6192-c12d-4b69-b658-62a4bcd63cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Define an Extension Function\n",
    "\n",
    "# We’ll use a lightweight AR(2) + linear trend hybrid.\n",
    "# It automatically falls back to a linear trend if AR(2) fails.\n",
    "\n",
    "\n",
    "def extend_feature(df, feature, id_cols=[\"pixel_id\", \"latitude\", \"longitude\"],\n",
    "                   year_col=\"year\", end_year=2030):\n",
    "    \"\"\"Extend each feature to 2030 using AR(2) or linear trend with fallback.\"\"\"\n",
    "    extended_rows = []\n",
    "\n",
    "    for _, g in df.groupby(id_cols):\n",
    "        g = g.sort_values(year_col)\n",
    "        years = g[year_col].values\n",
    "        values = g[feature].interpolate(limit_direction=\"both\").values  # fill NaN\n",
    "\n",
    "        if len(values) < 3:\n",
    "            continue  # skip short histories\n",
    "\n",
    "        # AR(2) coefficients (safe version)\n",
    "        y1, y2, y3 = values[-1], values[-2], values[-3]\n",
    "        denominator = (y2 - y3)\n",
    "        if abs(denominator) < 1e-9:\n",
    "            a, b = 1, 0\n",
    "        else:\n",
    "            a = (y1 - y2) / denominator\n",
    "            b = 1 - a\n",
    "\n",
    "\n",
    "        # # AR(2) coefficients (with fallback)\n",
    "        # y1, y2, y3 = values[-1], values[-2], values[-3]\n",
    "        # try:\n",
    "        #     a = (y1 - y2) / (y2 - y3)\n",
    "        #     b = 1 - a\n",
    "        # except ZeroDivisionError:\n",
    "        #     a, b = 1, 0\n",
    "\n",
    "        # Forecast yearly up to 2030\n",
    "        future_years = range(int(years.max()) + 1, end_year + 1)\n",
    "        y_prev2, y_prev1 = values[-2], values[-1]\n",
    "        y_future = []\n",
    "\n",
    "        for _ in future_years:\n",
    "            y_next = a * y_prev1 + b * y_prev2\n",
    "            if feature in [\"precipitation\", \"soil_moisture\", \"ch4_emissions\"]:\n",
    "                y_next = max(y_next, 0)  # avoid negatives\n",
    "            y_future.append(y_next)\n",
    "            y_prev2, y_prev1 = y_prev1, y_next\n",
    "\n",
    "        df_future = pd.DataFrame({\n",
    "            **{col: g[col].iloc[0] for col in id_cols},\n",
    "            year_col: list(future_years),\n",
    "            feature: y_future\n",
    "        })\n",
    "        extended_rows.append(df_future)\n",
    "\n",
    "    if not extended_rows:\n",
    "        print(f\"⚠️ No new rows generated for {feature}. Check missing data or ID grouping.\")\n",
    "        return df\n",
    "\n",
    "    df_extended = pd.concat([df, pd.concat(extended_rows)], ignore_index=True)\n",
    "    return df_extended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd2eb9-df74-4a4b-9a96-739e4459c20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c9e308-b4e1-4dac-8e3b-a3ef59ea4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending temperature...\n",
      "Extending precipitation...\n",
      "Extending soil_moisture...\n",
      "Extending permafrost_fraction...\n",
      "Extending ch4_emissions...\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Apply the Function to Each Dynamic Variable\n",
    "\n",
    "dynamic_vars = [\n",
    "    \"temperature\", \"precipitation\", \"soil_moisture\",\n",
    "    \"permafrost_fraction\", \"ch4_emissions\"\n",
    "]\n",
    "\n",
    "for var in dynamic_vars:\n",
    "    print(f\"Extending {var}...\")\n",
    "    df = extend_feature(df, var, end_year=2030)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f142a6-9c1a-4430-a00b-62d2d42b47f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bec19a-4e10-4c77-9f3c-19260506c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. Replicate Static Features\n",
    "# These features remain constant per pixel:\n",
    "\n",
    "static_vars = [\"elevation\", \"land_cover_class\", \"is_wetland_like\"]\n",
    "\n",
    "for var in static_vars:\n",
    "    df[var] = df.groupby(\"pixel_id\")[var].transform(\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e960d44-b51f-4a7f-8fde-480ae2108d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96de2abd-9595-4cbd-9ac2-d35766290b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extended dataset saved!\n",
      "[2010. 2011. 2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021.\n",
      " 2022. 2023. 2024. 2025. 2026. 2027. 2028. 2029. 2030.]\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"Unified_Climate_Dataset_2010-2030_ML_READY.csv\", index=False)\n",
    "print(\"✅ Extended dataset saved!\")\n",
    "print(df[\"year\"].unique())  # should show 2010–2030\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85603bfd-16b5-4dc5-b32d-2de376740130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c12ad9-8323-41e8-b259-23ca07d6e053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c50a762-52d3-4ae0-a65a-a3913f96d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: Unified_Climate_Dataset_2010-2030_FIXED.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Step 1: Load your clean base (up to 2024)\n",
    "df = pd.read_csv(\"Unified_Climate_Dataset_2010-2024_ML_READY_5.csv\")\n",
    "\n",
    "# ✅ Step 2: Define variable groups\n",
    "id_cols   = [\"pixel_id\", \"latitude\", \"longitude\"]\n",
    "year_col  = \"year\"\n",
    "dynamic   = [\"temperature\", \"precipitation\", \"soil_moisture\",\n",
    "             \"permafrost_fraction\", \"ch4_emissions\"]\n",
    "static    = [\"elevation\", \"land_cover_class\", \"is_wetland_like\"]\n",
    "\n",
    "start_y, end_y = 2025, 2030\n",
    "future_years = list(range(start_y, end_y + 1))\n",
    "\n",
    "# ✅ Step 3: Extension function (safe AR(2) with fallback)\n",
    "def extend_feature_from_base(base_df, feature):\n",
    "    rows = []\n",
    "    for _, g in base_df[[*id_cols, year_col, feature]].groupby(id_cols):\n",
    "        g = g.sort_values(year_col)\n",
    "        vals = g[feature].interpolate(limit_direction=\"both\").values\n",
    "        if len(vals) < 3:\n",
    "            continue\n",
    "\n",
    "        y1, y2, y3 = vals[-1], vals[-2], vals[-3]\n",
    "        denom = (y2 - y3)\n",
    "        if abs(denom) < 1e-9:\n",
    "            a, b = 1.0, 0.0\n",
    "        else:\n",
    "            a = (y1 - y2) / denom\n",
    "            b = 1.0 - a\n",
    "\n",
    "        yp2, yp1 = y2, y1\n",
    "        fut_vals = []\n",
    "        for _ in future_years:\n",
    "            y_next = a*yp1 + b*yp2\n",
    "            if feature in [\"precipitation\", \"soil_moisture\", \"ch4_emissions\"]:\n",
    "                y_next = max(y_next, 0.0)\n",
    "            fut_vals.append(y_next)\n",
    "            yp2, yp1 = yp1, y_next\n",
    "\n",
    "        rows.append(pd.DataFrame({\n",
    "            **{c: g[c].iloc[0] for c in id_cols},\n",
    "            year_col: future_years,\n",
    "            feature: fut_vals\n",
    "        }))\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=[*id_cols, year_col, feature])\n",
    "\n",
    "# ✅ Step 4: Create a future grid and extend each dynamic feature\n",
    "base = df[df[year_col] <= 2024].copy()\n",
    "keys = base[id_cols].drop_duplicates().copy()\n",
    "keys[\"_k\"] = 1\n",
    "years_df = pd.DataFrame({year_col: future_years})\n",
    "years_df[\"_k\"] = 1\n",
    "future = keys.merge(years_df, on=\"_k\").drop(columns=\"_k\")\n",
    "\n",
    "for feat in dynamic:\n",
    "    fut_feat = extend_feature_from_base(base, feat)\n",
    "    future = future.merge(fut_feat, on=[*id_cols, year_col], how=\"left\")\n",
    "\n",
    "for s in static:\n",
    "    map_s = base.groupby(\"pixel_id\")[s].first()\n",
    "    future[s] = future[\"pixel_id\"].map(map_s)\n",
    "\n",
    "future[\"ch4_concentration\"] = np.nan\n",
    "future[\"land_cover_name\"] = base.groupby(\"pixel_id\")[\"land_cover_name\"].first().reindex(future[\"pixel_id\"]).values\n",
    "\n",
    "# ✅ Step 5: Combine base + future\n",
    "df_2030 = pd.concat([base, future], ignore_index=True)\n",
    "df_2030.to_csv(\"Unified_Climate_Dataset_2010-2030_FIXED.csv\", index=False)\n",
    "print(\"✅ Saved: Unified_Climate_Dataset_2010-2030_FIXED.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea013ed-5a61-41db-b399-d4592f5c64a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc0d1f0-c59d-4180-9bbb-02490ff0c600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:32:44,289 | INFO | Extending temperature …\n",
      "2025-10-21 17:33:24,550 | INFO | temperature: done in 40.3s\n",
      "2025-10-21 17:33:24,550 | INFO | Extending precipitation …\n",
      "2025-10-21 17:34:04,068 | INFO | precipitation: done in 39.5s\n",
      "2025-10-21 17:34:04,069 | INFO | Extending soil_moisture …\n",
      "2025-10-21 17:34:44,054 | INFO | soil_moisture: done in 40.0s\n",
      "2025-10-21 17:34:44,055 | INFO | Extending permafrost_fraction …\n",
      "2025-10-21 17:35:24,072 | INFO | permafrost_fraction: done in 40.0s\n",
      "2025-10-21 17:35:24,073 | INFO | Extending ch4_emissions …\n",
      "2025-10-21 17:36:04,218 | INFO | ch4_emissions: done in 40.1s\n"
     ]
    }
   ],
   "source": [
    "import logging, time\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "for feat in dynamic:\n",
    "    t0 = time.perf_counter()\n",
    "    logging.info(f\"Extending {feat} …\")\n",
    "    fut_feat = extend_feature_from_base(base, feat)\n",
    "    if fut_feat.empty:\n",
    "        logging.warning(f\"{feat}: skipped (no rows).\")\n",
    "        continue\n",
    "    future = future.merge(fut_feat, on=[*id_cols, year_col], how=\"left\")\n",
    "    logging.info(f\"{feat}: done in {time.perf_counter()-t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9962ee-82db-48a5-bc74-80d1d30bfd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f68015-dc6b-4d96-a538-a2a10bea4ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2e727-62b0-4425-b01d-e8056c1aec58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
